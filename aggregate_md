# Aggregate a folder of .md files into a single .md file

from datetime import datetime
import os
ts_db = f"{datetime.now().strftime('%Y-%m-%d %H:%M')}"
ts_time = f"{datetime.now().strftime('%H:%M:%S')}"
print(f"\n---------- {ts_time} starting {os.path.basename(__file__)}")
import time
start_time = time.time()

import os
from pathlib import Path

# GLOBALS

test = 1
verbose = 1

count_row = 0
count_total = 0
count = 0

def aggregate_md_files(folder_path: str, output_file: str = None) -> str:
    """
    Aggregate all .md files in a folder (and subfolders) into a single .md file.
    
    Args:
        folder_path: Path to folder containing .md files
        output_file: Output path (default: {folder_name}.md in parent dir)
    
    Returns:
        str: Path to combined .md file
    """
    folder = Path(folder_path)
    
    if not folder.exists():
        raise FileNotFoundError(f"Folder not found: {folder_path}")
    
    # Default output: parent_dir/foldername.md
    if output_file is None:
        output_file = folder.parent / f"{folder.name}.md"
    else:
        output_file = Path(output_file)
        # If output_file is a directory, set a default filename inside it
        if output_file.exists() and output_file.is_dir():
            output_file = output_file / f"{folder.name}.md"
        elif not output_file.suffix:  # If no extension, treat as directory and append
            output_file = output_file / f"{folder.name}.md"
        # If file path parent directory does not exist, create it
        output_file.parent.mkdir(parents=True, exist_ok=True)

    # If the directory doesn't exist, create it (workaround for FileNotFoundError on write)
    if not output_file.parent.exists():
        output_file.parent.mkdir(parents=True, exist_ok=True)

    # Find all .md files recursively, sorted for consistent order
    md_files = sorted(folder.rglob("*.md"))
    
    if not md_files:
        print(f"‚ö†Ô∏è No .md files found in {folder_path}")
        return None
    
    print(f"üìÅ Found {len(md_files)} .md files in {folder.name}/")

    website_name = folder.name
    if "-website" in website_name:
        website_name = website_name.replace("-website", "")
    
    combined_content = []
    # combined_content.append(f"# {folder.name} - Combined Documentation\n")
    combined_content.append(f"""---
title: {website_name} - Website Knowledge Base
pages: {len(md_files)}
generated: {datetime.now().strftime("%Y-%m-%d %H:%M")}
type: knowledge-base
---
""")
    combined_content.append(f"""
## About This Document

This document is a **comprehensive knowledge base** compiled from the website content of **{folder.name}**. It was automatically generated by crawling and converting the website's HTML pages into Markdown format, then aggregating them into this single reference file.

### Purpose

This combined document serves as a complete textual representation of the {folder.name} website, intended for:

- **AI/LLM context**: Providing full website knowledge for AI assistants to answer questions about {folder.name}, its products, services, and company information
- **Search and retrieval**: Enabling semantic search across all website content
- **Knowledge extraction**: Facilitating analysis of company offerings, messaging, and documentation

### Document Structure

- **Source**: {folder_path}
- **Total pages**: {len(md_files)}
- **Generated**: {datetime.now().strftime("%Y-%m-%d %H:%M")}

Each section below represents a single page from the website. The section heading shows the original URL path, and the content is the main body text extracted from that page (excluding headers, footers, and navigation elements).

### How to Use This Document

When answering questions about {folder.name}:

1. **Search by topic**: Look for relevant section headings or keywords
2. **Cross-reference**: Information may span multiple pages
3. **Consider context**: Each section is a standalone page; some content may repeat across pages
4. **Source attribution**: Reference the section heading (URL path) when citing information

---

""")
    combined_content.append(f"_Aggregated from {len(md_files)} HTML files_\n\n")

    combined_content.append("---\n\n")
    
    # Table of contents
    combined_content.append("## Table of Contents\n\n")
    for i, md_file in enumerate(md_files, 1):
        rel_path = md_file.relative_to(folder)
        anchor = str(rel_path).replace("/", "-").replace(".md", "").replace("_", "-").lower()
        combined_content.append(f"{i}. [{rel_path}](#{anchor})\n")
    combined_content.append("\n---\n\n")
    
    # Aggregate content
    for md_file in md_files:
        rel_path = md_file.relative_to(folder)
        
        try:
            content = md_file.read_text(encoding="utf-8", errors="ignore").strip()
        except Exception as e:
            print(f"  ‚ö†Ô∏è Error reading {rel_path}: {e}")
            continue
        
        # Skip empty files
        if not content:
            continue
        
        # Add section header
        combined_content.append(f"## {rel_path}\n\n")
        combined_content.append(content)
        combined_content.append("\n\n---\n\n")
        
        print(f"  ‚úì {rel_path} ({len(content):,} chars)")
    
    # Write combined file
    final_content = "".join(combined_content)
    output_file.write_text(final_content, encoding="utf-8")
    
    size_mb = output_file.stat().st_size / 1024 / 1024
    print(f"\n‚úÖ Combined: {output_file}")
    print(f"   Size: {size_mb:.2f} MB ({len(final_content):,} chars)")
    
    return str(output_file)

########################################################################################################

if __name__ == '__main__':
    print('\n\n-------------------------------')
    # print(f"\ncount_row:\t{count_row:,}")
    # print(f"count_total:\t{count_total:,}")
    # print(f"count:\t\t{count:,}")

    input_folder = "/Users/nic/dl/telekom-mms-website"
    output_folder = "/Users/nic/ai/websites"

    aggregate_md_files(input_folder, output_folder)

    run_time = round((time.time() - start_time), 3)
    if run_time < 1:
        print(f'\n{os.path.basename(__file__)} finished in {round(run_time*1000)}ms at {datetime.now().strftime("%H:%M:%S")}.\n')
    elif run_time < 60:
        print(f'\n{os.path.basename(__file__)} finished in {round(run_time)}s at {datetime.now().strftime("%H:%M:%S")}.\n')
    elif run_time < 3600:
        print(f'\n{os.path.basename(__file__)} finished in {round(run_time/60)}mns at {datetime.now().strftime("%H:%M:%S")}.\n')
    else:
        print(f'\n{os.path.basename(__file__)} finished in {round(run_time/3600, 2)}hrs at {datetime.now().strftime("%H:%M:%S")}.\n')